{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3d8923aa",
      "metadata": {
        "id": "3d8923aa"
      },
      "source": [
        "\n",
        "# Introducción a Redes Neuronales Convolucionales (CNNs)\n",
        "\n",
        "Las redes neuronales convolucionales (CNNs) son un tipo especial de red neuronal muy utilizada en el procesamiento y análisis de imágenes. En este notebook aprenderás los fundamentos teóricos y prácticos, y realizarás tu primera clasificación de imágenes usando Python y Keras.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. ¿Qué es una CNN?\n",
        "\n",
        "Una CNN es una red diseñada para procesar datos con una estructura de cuadrícula, como imágenes. Sus aplicaciones más conocidas incluyen:\n",
        "- Reconocimiento de objetos en fotos\n",
        "- Detección de caras\n",
        "- Diagnóstico médico por imagen\n",
        "\n",
        "### Componentes principales de una CNN:\n",
        "- **Capa convolucional (Conv2D)**: Aplica filtros para detectar patrones locales.\n",
        "- **Capa de activación (ReLU)**: Añade no linealidad.\n",
        "- **Capa de agrupamiento (Pooling)**: Reduce el tamaño y complejidad (ej. MaxPooling).\n",
        "- **Capa densa (Dense)**: Conecta todo para tomar la decisión final (clasificación).\n",
        "\n",
        "![CNN Architecture](https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6459e6bc",
      "metadata": {
        "id": "6459e6bc"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## 2. Visualización: ¿Qué hace una convolución?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3541e3ac",
      "metadata": {
        "id": "3541e3ac",
        "outputId": "eea4fe7f-0b6e-448c-adef-663996ccba05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import convolve2d\n",
        "\n",
        "# Imagen simple (blanco y negro)\n",
        "image = np.zeros((10, 10))\n",
        "image[2:8, 2:8] = 1\n",
        "\n",
        "# Filtro para detección de bordes horizontales\n",
        "kernel = np.array([[1, 1, 1],\n",
        "                   [0, 0, 0],\n",
        "                   [-1, -1, -1]])\n",
        "\n",
        "filtered_image = convolve2d(image, kernel, mode='same')\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.title('Imagen original')\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.title('Filtro')\n",
        "plt.imshow(kernel, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.title('Imagen filtrada')\n",
        "plt.imshow(filtered_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f2b14c0",
      "metadata": {
        "id": "9f2b14c0"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## 3. Construye tu primera CNN con Keras\n",
        "\n",
        "### Vamos a clasificar dígitos escritos a mano con el dataset MNIST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dd3dfa9b",
      "metadata": {
        "id": "dd3dfa9b",
        "outputId": "163e7840-c03e-43eb-9cfc-9ffd67e83f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m102,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121,930\u001b[0m (476.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,930</span> (476.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m121,930\u001b[0m (476.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,930</span> (476.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 55ms/step - accuracy: 0.8673 - loss: 0.4447 - val_accuracy: 0.9853 - val_loss: 0.0580\n",
            "Epoch 2/3\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 54ms/step - accuracy: 0.9813 - loss: 0.0617 - val_accuracy: 0.9878 - val_loss: 0.0430\n",
            "Epoch 3/3\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 52ms/step - accuracy: 0.9879 - loss: 0.0377 - val_accuracy: 0.9882 - val_loss: 0.0374\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9841 - loss: 0.0437\n",
            "Precisión en test: 0.99\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# 1. Cargar los datos\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train[..., np.newaxis] / 255.0\n",
        "X_test = X_test[..., np.newaxis] / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Definir el modelo\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 3. Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 4. Entrenar\n",
        "history = model.fit(X_train, y_train, epochs=3, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# 5. Evaluar\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Precisión en test: {test_acc:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29d29505",
      "metadata": {
        "id": "29d29505"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## 4. Ejercicio Propuesto\n",
        "\n",
        "- Modifica la arquitectura para usar **más filtros** o **más capas**.\n",
        "- Cambia la función de activación por `tanh` o `sigmoid`.\n",
        "- Usa el dataset CIFAR-10 (`from tensorflow.keras.datasets import cifar10`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76c427f8",
      "metadata": {
        "id": "76c427f8"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## 5. Recursos adicionales\n",
        "\n",
        "- [DeepLearning.AI - Curso CNNs (Coursera)](https://www.coursera.org/learn/convolutional-neural-networks)\n",
        "- [TensorFlow Tutorial CNN](https://www.tensorflow.org/tutorials/images/cnn)\n",
        "- [Visualización de CNNs en Playground](https://poloclub.github.io/cnn-explainer/)\n",
        "\n",
        "---\n",
        "\n",
        "¿Listo para experimentar? ¡Modifica, ejecuta y aprende!\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}